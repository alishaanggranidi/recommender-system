# -*- coding: utf-8 -*-
"""Recommender System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bRj2EXUyqVKmRkVrWFiAr2xkQyrYr0eB

# Proyek Recommendation System

- **Nama:** Alisha Anggranidi Salsabila
- **Email:** anggranidi@gmail.com
- **ID Dicoding:** MC012D5X2354

## Data Understanding

Mengimpor library yang diperlukan untuk seluruh proyek
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path

"""## Data Loading

Mengunduh dataset dari kaggle: https://www.kaggle.com/datasets/meirnizri/cellphones-recommendations
"""

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d meirnizri/cellphones-recommendations

#unzip dataset
!unzip cellphones-recommendations.zip
print("Unzip data berhasil dilakukan")

"""****
Mengganti nama file agar lebih praktis saat digunakan.

- cellphones data.csv → cdata.csv
- cellphones rating.csv → crating.csv
- cellphones users.csv → cusers.csv









"""

!mkdir dataset
!mv 'cellphones data.csv' 'dataset/cellphones data.csv'
!mv 'cellphones ratings.csv' 'dataset/cellphones ratings.csv'
!mv 'cellphones users.csv' 'dataset/cellphones users.csv'

#change nama file
!mv 'dataset/cellphones data.csv' 'cdata.csv'
!mv 'dataset/cellphones ratings.csv' 'cratings.csv'
!mv 'dataset/cellphones users.csv' 'cusers.csv'

"""Hasil dari kode di atas menunjukkan bahwa dataset terdiri dari 3 file .csv, yaitu:

1. cellphones data.csv: Menyimpan informasi mengenai data cellphone, seperti nama brand, nama cellphone, sistem operasi, dan lain-lain.
2. cellphones ratings.csv: Berisi informasi tentang cellphone dan rating yang diberikan oleh pengguna terhadap cellphone tersebut.
3. cellphones users.csv: Menyimpan data identitas pengguna, seperti usia, jenis kelamin, dan pekerjaan.
"""

#menyimpan csv pada suatu variabel
data = pd.read_csv('cdata.csv')
ratings = pd.read_csv('cratings.csv')
users = pd.read_csv('cusers.csv')

#show info dari dataset data
data.info()

"""****
Hasil dari kode di atas menunjukkan informasi berikut:

- Jumlah baris sebanyak 33 dan kolom sebanyak 14
- Terdapat 10 kolom dengan tipe data numerik dan 4 kolom dengan tipe data objek
"""

#show 5 data dari variabel data
data.head()

#show info dari dataset ratings
ratings.info()

"""****
Hasil dari kode di atas menunjukkan Jumlah baris sebanyak 990 dan 3 kolom dengan 3 kolom bertipe data numerik
"""

#show 5 data dari variabel ratings
ratings.head()

#show info dari dataset users
users.info()

"""****
Hasil dari kode di atas menunjukkan informasi berikut:

- Terdiri dari 99 baris dan 4 kolom
- 2 kolom bertipe data numerik dan 2 kolom bertipe data object
"""

#show 5 data dari variabel users
users.head()

"""## Univariate Exploratory Data Analysis

Daftar variabel pada masing-masing dataset:

1. data:
* `cellphone_id`: Unik ID untuk setiap ponsel.
* `brand`: Merek ponsel.
* `model`: Model ponsel.
* `operating system`: Sistem operasi yang digunakan oleh ponsel.
* `internal memory`: Kapasitas memori internal ponsel dalam GB.
* `RAM`: Kapasitas RAM ponsel dalam GB.
* `performance`: Skor kinerja ponsel.
* `main camera`: Resolusi kamera utama dalam MP.
* `selfie camera`: Resolusi kamera depan dalam MP.
* `battery size`: Kapasitas baterai ponsel dalam mAh.
* `screen size`: Ukuran layar ponsel dalam inci.
* `weight`: Berat ponsel dalam gram.
* `price`: Harga ponsel dalam USD.
* `release date`: Tanggal rilis ponsel.

2. rating:
* `user_id`: Unik ID untuk setiap pengguna.
* `cellphone_id`: Unik ID untuk setiap ponsel (merujuk pada cellphones_data).
* `rating`: Nilai rating yang diberikan pengguna untuk ponsel tertentu (skala 1-10).

3. user:

* `user_id`:Unik ID untuk setiap pengguna.
* `age`: Usia pengguna.
* `gender`: Jenis kelamin pengguna.
* `occupation`: Pekerjaan pengguna.

### Data

Menguji jumlah cellphone berdasarkan setiap brand
"""

print('Total seluruh brand: ',len(data.brand.unique()))

#masing-masing brand
brand_counts = data['brand'].value_counts()
print(brand_counts)

#show grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=data, x=data['brand'], color='#FFB6C1')
plt.xticks(rotation=90)
plt.show()

"""Hasil dari kode di atas menunjukkan informasi berikut:

- Terdapat 10 brand yang berbeda
- Brand dengan jumlah ponsel terbanyak adalah Samsung
- Sedangkan brand dengan jumlah ponsel paling sedikit adalah Asus, Oppo, Vivo, dan Sony

****
Menampilkan seluruh jenis model cellphone
"""

model_counts = data['model'].value_counts()
print('Total seluruh cellphone: ', len(model_counts))
model_counts

"""Berdasarkan hasil dari kode di atas, terdapat 33 model cellphone yang berbeda

****
Menghitung jumlah operating system untuk setiap kategori
"""

os_counts = data['operating system'].value_counts()
print(os_counts)

#show grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=data, x=data['operating system'], color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas menunjukkan bahwa terdapat dua kategori sistem operasi, dengan tipe sistem operasi Android memiliki jumlah terbanyak, yaitu 27

****
Menghitung seluruh internal memory untuk setiap kategori
"""

internal_memory_counts = data['internal memory'].value_counts()
print(internal_memory_counts)

#show grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=data, x=data['internal memory'], color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas menunjukkan informasi berikut:

- Terdapat 5 kategori memori internal.
- Kategori memori internal 128 GB memiliki jumlah terbanyak, yaitu 20 unit, sementara kategori memori internal 512 GB memiliki jumlah paling sedikit, hanya 1 unit

****
Menghitung seluruh RAM untuk setiap kategori
"""

RAM_counts = data['RAM'].value_counts()
print(RAM_counts)

#show grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=data, x=data['RAM'], color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas menunjukkan informasi berikut:

- Terdapat 5 kategori RAM.
- Kategori RAM 8 memiliki jumlah terbanyak, yaitu 13.
- Kategori RAM 3 dan RAM 12 memiliki jumlah paling sedikit, masing-masing 4.

****
Menampilkan analisis untuk kolom 'performance'. Analisis dilakukan dengan membagi kolom tersebut menjadi dua kategori karena nilai yang ada sangat bervariasi
"""

#filter
performance_above5 = data[data['performance'] > 5]
performance_below5 = data[data['performance'] <= 5]

#count
total_above5 = len(performance_above5)
total_below5 = len(performance_below5)

print('Jumlah data dengan performance lebih dari 5:', total_above5)
print('Jumlah data dengan performance kurang dari sama dengan 5:', total_below5)

performance_data = pd.DataFrame({
    'Category' : ['Performance > 5', 'Performance <= 5'],
    'Count' : [total_above5, total_below5]
})
#show grafik
plt.figure(figsize=(5, 3))
sns.barplot(data=performance_data, x='Category', y='Count', color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas: Terdapat 23 ponsel dengan skor kinerja lebih dari lima, sementara 10 ponsel lainnya memiliki skor kinerja kurang dari lima

****
Menghitung jumlah main camer untuk setiap kategori
"""

mainCamera_counts = data['main camera'].value_counts()
print(mainCamera_counts)

#show grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=data, x=data['main camera'], color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas menunjukkan informasi berikut:

- Terdapat 6 kategori kamera utama
- Kategori main camera `50` memiliki jumlah terbanyak, yaitu 13.
- Kategori main camera `13`, `48`, dan `108` memiliki jumlah paling sedikit, masing-masing 2

****
Menghitung battery size untuk setiap kategori
"""

batterySize_counts = data['battery size'].value_counts()
print(batterySize_counts)

#show grafik
plt.figure(figsize=(15, 3))
sns.countplot(data=data, x=data['battery size'], color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas menunjukkan informasi berikut:

- Terdapat 18 kategori ukuran baterai.
- Kategori ukuran baterai `5000` memiliki jumlah terbanyak, yaitu 11.

****
Menghitung screen size untuk setiap kategori
"""

screenSize_counts = data['screen size'].value_counts()
print(screenSize_counts)

#show grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=data, x=data['screen size'], color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas menunjukkan informasi berikut:

- Terdapat sepuluh kategori Screen Size
- Kategori ukuran layar `6.7` memiliki jumlah terbanyak, yaitu 8

****
Menghitung jumlah weight untuk setiap kategori
"""

weighted_counts = data['weight'].value_counts()
print('Jumlah setiap kategori berat:', len(weighted_counts))

#group
from collections import defaultdict
freq_groups = defaultdict(list)
for weight, count in weighted_counts.items():
    freq_groups[count].append(weight)
for count in sorted(freq_groups.keys(), reverse=True):
    weights = sorted(freq_groups[count])
    weights_str = ' '.join(map(str, weights))
    print(f"{count}: {weights_str}")

#show grafik
plt.figure(figsize=(15, 3))
sns.countplot(data=data, x=data['weight'], color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas menunjukkan informasi berikut:

- Terdapat 27 kategori weight
- Kategori berat `204` memiliki jumlah terbanyak, yaitu 5

****
Analisis release date berdasarkan tahun
"""

data_new = data.copy()
data_new['release date'] = pd.to_datetime(data['release date'], format='%d/%m/%Y')
data_new['release_year'] = data_new['release date'].dt.year
release_year_counts = data_new['release_year'].value_counts().sort_index()
print(release_year_counts)

#show grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=data, x=data_new['release_year'], color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas menunjukkan informasi berikut:

- Terdapat 3 kategori tahun.
- Tahun 2021 dan 2022 memiliki jumlah terbanyak, masing-masing dengan total 16
- Tahun 2018 memiliki jumlah paling sedikit, yaitu 1

### Rating

Melakukan analisis jumlah review yang dilakukan oleh setiap pengguna dan memeriksa apakah ada pengguna yang memiliki jumlah review yang berbeda dibandingkan dengan pengguna lainnya.
"""

user_review_counts = ratings['user_id'].value_counts()
print(user_review_counts)

#nilai unik
print(f"Jumlah nilai unik review: {user_review_counts.unique()}")

"""Hasil dari kode di atas menunjukkan bahwa setiap pengguna memberikan review sebanyak sepuluh kali, dan semua pengguna memiliki jumlah review yang sama, yaitu sepuluh

****
Menghitung frekuensi kemunculan cellphone yang direview
"""

cellphone_review_counts = ratings['cellphone_id'].value_counts()
print("Jumlah frekuensi kemunculan setiap cellphone:")
print(cellphone_review_counts.sort_index())

#nilai unik
print("Minimum:", cellphone_review_counts.min())
print("Maximum:", cellphone_review_counts.max())

#show grafik
plt.figure(figsize=(15,3))
sns.countplot(data=ratings, x=ratings['cellphone_id'], color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas menunjukkan bahwa ponsel yang paling sering direview memiliki total 41 review, sementara ponsel yang paling sedikit direview hanya memiliki 20 review

****
Menghitung jumlah rating untuk setiap kategori
"""

ratings_counts = ratings['rating'].value_counts()
print("\nJumlah frekuensi setiap rating:\n", ratings_counts.sort_index())

#show grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=ratings, x=ratings['rating'], color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas menunjukkan informasi berikut:

- Skala rating berkisar antara 0 hingga 10.
- Rating terbanyak memiliki nilai 8 dan rating tersedikit memiliki nilai 3
- Terdapat outliers, yaitu rating dengan nilai 18.

### User
"""

#count age X muncul berapa kali
age_counts = users['age'].value_counts()
print("\nTotal frekuensi age:\n", age_counts.sort_index())

#show grafik
plt.figure(figsize=(10, 3))
sns.countplot(data=users, x=users['age'], color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas menunjukkan informasi berikut:

- Usia tertua dari pengguna adalah 61 tahun
- Usia termuda dari pengguna adalah 21 tahun
- Pengguna dengan usia 25 tahun memiliki jumlah terbanyak, yaitu 12

****
Menghitung seluruh kategori gender
"""

user_counts = users['gender'].value_counts()
print("\nTotal frekuensi gender:\n", user_counts)

#show grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=users, x=users['gender'], color='#FFB6C1')
plt.show()

"""Hasil dari kode di atas menunjukkan informasi berikut:

- Jumlah pengguna dengan gender female adalah 46
- Jumlah pengguna dengan gender male adalah 50
- Terdapat outliers, yaitu kategori `Select Gender`

****
menghitung jumlah munculnya occupation
"""

occupation_counts = users['occupation'].str.lower().value_counts()
print('Total occupation: ', len(occupation_counts))
print("\nTotal frekuensi occupation:\n", occupation_counts)

"""Hasil dari kode di atas menunjukkan informasi berikut:

- Terdapat 45 jenis pekerjaan
- Terdapat kesalahan penulisan pada kata `healthare`
- Pekerjaan `information technology` dan `it` dapat digabungkan

## Data Preprocessing
"""

#menggabungkan dataset data, ratings, dan users
ratings_data = pd.merge(ratings, data, on='cellphone_id')
merged_data = pd.merge(ratings_data, users, on='user_id')
merged_data.head()

#check missing value
merged_data.isnull().sum()

"""Hasil dari kode di atas menunjukkan terdapat 10 missing value pada kolom occupation

****
Menampilkan data dari baris yang memiliki missing value
"""

rows_with_missing_values = merged_data[merged_data.isnull().any(axis=1)]
print(rows_with_missing_values)

"""Hasil dari kode di atas menunjukkan bahwa, sebagaimana ditemukan dalam analisis univariate, terdapat outlier pada kolom gender, yaitu `Select Gender`, yang ternyata terkait dengan nilai NaN pada kolom occupation. Oleh karena itu, akan dilakukan drop"""

#drop missing value
merged_data = merged_data.dropna()

#check missing value
merged_data.isnull().sum()

"""Setelah melakukan drop, tidak ada lagi missing value"""

merged_data = merged_data.copy()
merged_data['occupation'] = merged_data['occupation'].str.lower()
merged_data['occupation'] = merged_data['occupation'].replace('healthare', 'healthcare')
merged_data['occupation'] = merged_data['occupation'].replace('it', 'information technology')

print("Data occupation berhasil dimodifikasi")

#show dataset
clean_data = merged_data
clean_data

"""## Data Preparation"""

#delete data yang duplikat
clean_data = clean_data.drop_duplicates('cellphone_id')

#konversi data series menjadi list
cellphone_id = clean_data['cellphone_id'].tolist()
brand = clean_data['brand'].tolist()
model = clean_data['model'].tolist()
operating_system = clean_data['operating system'].tolist()

print(len(cellphone_id))
print(len(brand))
print(len(model))
print(len(operating_system))

"""Membuat kamus untuk menentukan pasangan key-value. Karena TF-IDF hanya berlaku untuk data teks, maka hanya kolom dengan tipe data objek yang dipilih"""

#dictionary untuk menentukan pasangan key-value
data_dict = pd.DataFrame ({
    'cellphone_id': cellphone_id,
    'brand': brand,
    'model': model,
    'operating_system': operating_system
})

data_dict

"""Assign datafram ke variabel baru"""

data = data_dict
print("assign berhasil")

tf = TfidfVectorizer()
tf.fit(data['brand'])
tf.get_feature_names_out()

#fit dan transform ke matriks
tfidf_matrix = tf.fit_transform(data['brand'])
tfidf_matrix.shape

tfidf_matrix.todense()

"""****
Menampilkan matriks TF-IDF untuk beberapa model dan brand
"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.model
).sample(10, axis=1).sample(10, axis=0)

"""## Model Development dengan Content Based Filtering

Menghitung similarity degree antar model dengan teknik cosine similarity
"""

cosine_similarity = cosine_similarity(tfidf_matrix)
cosine_similarity

"""Matriks kesamaan untuk setiap model dengan menampilkan nama model pada 33 sampel kolom (axis = 1) dan 10 sampel baris (axis = 0)."""

cosine_similarity_df = pd.DataFrame(cosine_similarity, index=data['model'], columns=data['model'])
print('Shape:', cosine_similarity_df.shape)
cosine_similarity_df.sample(33, axis=1).sample(10, axis=0)

#fungsi model_recommendations
def model_recommendations(model, similarity_data=cosine_similarity_df, items=data_dict[['model', 'brand', 'operating_system']], k=4):
    index = similarity_data.loc[:, model].to_numpy().argpartition(range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(model, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

#show hasil rekomendasi untuk Galaxy S22 Ultra
model_recommendations('Galaxy S22 Ultra')

#show hasil rekomendasi untuk Galaxy S22 Ultra
model_recommendations('iPhone XR')

def precision_at_k(recommended_items, relevant_items, k):
    if k > len(recommended_items):
        k = len(recommended_items)

    if k == 0:
        return 0.0
    recommended_at_k = recommended_items[:k]
    print(f"Recommended at k: {recommended_at_k}")
    print(f"Relevant items: {relevant_items}")

    intersection = set(recommended_at_k) & relevant_items
    print(f"Intersection at k: {intersection}")

    num_relevant_at_k = len(intersection)
    return num_relevant_at_k / k

recommended_models_galaxy = ['Galaxy Z Flip 3', 'Galaxy S22 Plus', 'Galaxy Z Fold 3']
relevant_models_galaxy = set(['Galaxy S22', 'Galaxy S22 Ultra', 'Galaxy S22 Plus'])
k_value = 3
precision_k_galaxy = precision_at_k(recommended_models_galaxy, relevant_models_galaxy, k_value)
print(f"Precision@{k_value} for Galaxy recommendations: {precision_k_galaxy}")

recommended_models_iphone = ['iPhone 13', 'iPhone 13 Mini', 'iPhone SE (2022)', 'iPhone 13 Pro']
relevant_models_iphone = set(['iPhone 13 Pro Max', 'iPhone 14', 'iPhone 13', 'iPhone XR'])
k_value_iphone = 4
precision_k_iphone = precision_at_k(recommended_models_iphone, relevant_models_iphone, k_value_iphone)
print(f"Precision@{k_value_iphone} for iPhone XR recommendations: {precision_k_iphone}")

#save dataset ratings pada variabel df
df = ratings
df

#encode fitur user_id
user_ids = df['user_id'].unique().tolist()
print('List ID: ', user_ids)

user2user_encoded = {x: i for i, x in enumerate(user_ids)}
print('Encoded: ', user2user_encoded)

userencoded2user = {i: x for i, x in enumerate(user_ids)}
print('Encoded ke angka: ', userencoded2user)

#encode fitur cellphone_id
cellphone_ids = df['cellphone_id'].unique().tolist()
cellphone2cellphone_encoded = {x: i for i, x in enumerate(cellphone_ids)}
cellphoneencoded2cellphone = {i: x for i, x in enumerate(cellphone_ids)}

#mapping user_id dan cellphone_id
df['user'] = df['user_id'].map(user2user_encoded)
df['cellphone'] = df['cellphone_id'].map(cellphone2cellphone_encoded)

#show jumlah user
num_users = len(user2user_encoded)

#show jumlah cellphone
num_cellphones = len(cellphone2cellphone_encoded)

#change ratings menjadi float
df['rating'] = df['rating'].values.astype(np.float32)

#minimum rating
min_rating = min(df['rating'])

#maximum rating
max_rating = max(df['rating'])

print('Jumlah Pengguna: {}, Jumlah Ponsel: {}, Rating Minimum: {}, Rating Maksimum: {}'.format(
    num_users, num_cellphones, min_rating, max_rating
))

"""Hasil dari kode di atas menunjukkan bahwa terdapat outlier pada fitur rating, yaitu nilai `18`. Outlier tersebut perlu di drop"""

#drop rating 18
df = df[df['rating'] != 18]

#check nilai max tidak lebih dari 10
min_ratings = min(df['rating'])
max_ratings = max(df['rating'])

print('Minimal ratings: {}, Maximum ratings: {}' .format (min_ratings, max_ratings))

#random dataset
df = df.sample(frac=1, random_state=42)

#mapping data user dan cellphone menjadi satu value
x = df[['user', 'cellphone']].values
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

#split dataset dengan komposisi 80:20
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:],
)

print(x,y)

#recmmenderNet
import tensorflow as tf
class RecommenderNet(tf.keras.Model):
    def __init__(self, num_users, num_cellphones, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_cellphones = num_cellphones
        self.embedding_size = embedding_size
        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1)
        self.cellphone_embedding = layers.Embedding(
            num_cellphones,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.cellphone_bias = layers.Embedding(num_cellphones, 1)
    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        cellphone_vector = self.cellphone_embedding(inputs[:, 1])
        cellphone_bias = self.cellphone_bias(inputs[:, 1])

        dot_user_cellphone = tf.tensordot(user_vector, cellphone_vector, 2)
        x = dot_user_cellphone + user_bias + cellphone_bias
        return tf.nn.sigmoid(x)

#inisialisasi model dan compile
model = RecommenderNet(num_users, num_cellphones, embedding_size=50)
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics = [tf.keras.metrics.RootMeanSquaredError()]
)

#training
history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=8,
    epochs=100,
    validation_data=(x_val, y_val)
)

#show grafik proses
train_color = "#AEC6CF"
test_color = "#FFB6C1"

plt.plot(history.history['root_mean_squared_error'], color=train_color)
plt.plot(history.history['val_root_mean_squared_error'], color=test_color)
plt.title('Model Metrics')
plt.ylabel('Root Mean Squared Error')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""****

"""

#membuat variabel untuk direkomendasikan
phone_df = data_dict
df = pd.read_csv('cratings.csv')

#sample user
user_id  = df.user_id.sample(1).iloc[0]
cellphone_review_counts = df[df.user_id == user_id]

cellphone_not_review = phone_df[~phone_df['cellphone_id'].isin(cellphone_review_counts.cellphone_id.values)]['cellphone_id']
cellphone_not_review = list(
    set(cellphone_not_review)
    .intersection(set(cellphone2cellphone_encoded.keys()))
)

cellphone_not_review = [[cellphone2cellphone_encoded.get(x)]for x in cellphone_not_review]
user_encoder = user2user_encoded.get(user_id)
user_cellphone_array = np.hstack(
    ([[user_encoder]] * len(cellphone_not_review), cellphone_not_review)
)

ratings = model.predict(user_cellphone_array).flatten()
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_cellphones_ids = [
    cellphoneencoded2cellphone.get(cellphone_not_review[x][0]) for x in top_ratings_indices
]

print('Show recommendations for users: {}'.format(user_id))
print('----' *10 )
print('Cellphone with high rating from user')
print('----' *10 )

top_cellphones_user = (
    cellphone_review_counts.sort_values(by='rating', ascending=False)
    .head(5)
    .cellphone_id.values )

cellphone_df_rows = phone_df[phone_df['cellphone_id'].isin(top_cellphones_user)]
for row in cellphone_df_rows.itertuples():
  print(row.brand, ':', row.model)


print('----' * 10)
print('Top 10 cellphone recommendation for user')
print('----' * 10)

recommended_cellphones = phone_df[phone_df['cellphone_id'].isin(recommended_cellphones_ids)]
for row in recommended_cellphones.itertuples():
  print(row.brand, ':', row.model)